{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import torch\n",
    "import argparse\n",
    "import torch.nn as nn\n",
    "from torchview import draw_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int = 256):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = in_channels\n",
    "\n",
    "        self.reflectionpad2d = 1\n",
    "        self.kernel_size = 3\n",
    "        self.stride_size = 1\n",
    "\n",
    "        self.layers = []\n",
    "\n",
    "        for index in range(2):\n",
    "            self.layers.append(nn.ReflectionPad2d(self.reflectionpad2d))\n",
    "\n",
    "            self.layers.append(\n",
    "                nn.Conv2d(\n",
    "                    in_channels=self.in_channels,\n",
    "                    out_channels=self.out_channels,\n",
    "                    kernel_size=self.kernel_size,\n",
    "                    stride=self.stride_size,\n",
    "                )\n",
    "            )\n",
    "\n",
    "            self.layers.append(nn.InstanceNorm2d(num_features=self.out_channels))\n",
    "\n",
    "            if index != 1:\n",
    "                self.layers.append(nn.ReLU())\n",
    "\n",
    "        self.residualBlock = nn.Sequential(*self.layers)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        if isinstance(x, torch.Tensor):\n",
    "            return x + self.residualBlock(x)\n",
    "        else:\n",
    "            raise ValueError(\"Input should be the tensor type\".capitalize())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    image_channels = 256\n",
    "    residual = nn.Sequential(\n",
    "        *[ResidualBlock(in_channels=image_channels) for _ in range(3)]\n",
    "    )\n",
    "\n",
    "    print(residual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels: int = 3, sharedBlocks=None):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = int(math.pow(2, self.in_channels + self.in_channels))\n",
    "        self.kerenl_size = (self.in_channels * 2) + 1\n",
    "\n",
    "        if not isinstance(sharedBlocks, ResidualBlock):\n",
    "            raise ValueError(\n",
    "                \"shared_block must be an instance of ResidualBlock\".capitalize()\n",
    "            )\n",
    "\n",
    "        self.sharedBlocks = sharedBlocks\n",
    "\n",
    "        self.modelBlocks = list()\n",
    "        self.downLayers = list()\n",
    "\n",
    "        self.modelBlocks.append(\n",
    "            nn.Sequential(\n",
    "                nn.ReflectionPad2d(padding=self.in_channels),\n",
    "                nn.Conv2d(\n",
    "                    in_channels=self.in_channels,\n",
    "                    out_channels=self.out_channels,\n",
    "                    kernel_size=self.kerenl_size,\n",
    "                ),\n",
    "                nn.InstanceNorm2d(num_features=self.out_channels),\n",
    "                nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        for _ in range(2):\n",
    "            self.downLayers.append(\n",
    "                nn.Conv2d(\n",
    "                    in_channels=self.out_channels,\n",
    "                    out_channels=self.out_channels * 2,\n",
    "                    kernel_size=self.kerenl_size // 2,\n",
    "                    stride=(self.in_channels // self.in_channels) + 1,\n",
    "                    padding=self.in_channels // self.in_channels,\n",
    "                )\n",
    "            )\n",
    "            self.downLayers.append(\n",
    "                nn.InstanceNorm2d(num_features=self.out_channels * 2)\n",
    "            )\n",
    "            self.downLayers.append(nn.ReLU())\n",
    "\n",
    "            self.out_channels *= 2\n",
    "\n",
    "        self.modelBlocks.append(nn.Sequential(*self.downLayers))\n",
    "\n",
    "        self.modelBlocks.append(\n",
    "            nn.Sequential(\n",
    "                *[ResidualBlock(in_channels=self.out_channels) for _ in range(3)]\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.modelBlocks = nn.Sequential(*self.modelBlocks)\n",
    "\n",
    "    def reparameterization(self, mu: torch.Tensor):\n",
    "        if isinstance(mu, torch.Tensor):\n",
    "            z = torch.randn_like(mu)\n",
    "            return mu + z\n",
    "        else:\n",
    "            raise ValueError(\"Input should be the tensor type\".capitalize())\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        if isinstance(x, torch.Tensor):\n",
    "            x = self.modelBlocks(x)\n",
    "            mu = self.sharedBlocks(x)\n",
    "            z = self.reparameterization(mu)\n",
    "\n",
    "            return mu, z\n",
    "        else:\n",
    "            raise ValueError(\"Input should be the tensor type\".capitalize())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    in_channels = 3\n",
    "\n",
    "    batch_size = 1\n",
    "    image_size = 128\n",
    "\n",
    "    shared_E = ResidualBlock(\n",
    "        in_channels=int(in_channels * (math.pow(2, 8) - 1) / in_channels + 1)\n",
    "    )\n",
    "\n",
    "    encoder1 = Encoder(in_channels=in_channels, sharedBlocks=shared_E)\n",
    "    encoder2 = Encoder(in_channels=in_channels, sharedBlocks=shared_E)\n",
    "\n",
    "    mu1, z1 = encoder1(torch.randn(batch_size, in_channels, image_size, image_size))\n",
    "    mu2, z2 = encoder2(torch.randn(batch_size, in_channels, image_size, image_size))\n",
    "\n",
    "    assert (\n",
    "        mu1.size() == mu2.size() == z1.size() == z2.size()\n",
    "    ), \"Shape mismatch(mu1, mu2) and (z1, z2)\".capitalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, in_channels: int = 256, sharedBlock: ResidualBlock = None):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = self.in_channels\n",
    "\n",
    "        self.kernel_size = int(math.sqrt(math.sqrt(self.in_channels)))\n",
    "        self.stride_size = int(math.sqrt(self.kernel_size))\n",
    "        self.padding_size = self.stride_size // self.stride_size\n",
    "\n",
    "        if isinstance(sharedBlock, ResidualBlock):\n",
    "            self.sharedBlock = sharedBlock\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"shared_block must be an instance of ResidualBlock\".capitalize()\n",
    "            )\n",
    "\n",
    "        self.modelBlocks = []\n",
    "        self.upsampleBlocks = []\n",
    "\n",
    "        self.modelBlocks.append(\n",
    "            nn.Sequential(\n",
    "                *[ResidualBlock(in_channels=self.in_channels) for _ in range(3)]\n",
    "            )\n",
    "        )\n",
    "\n",
    "        for _ in range(2):\n",
    "            self.upsampleBlocks.append(\n",
    "                nn.ConvTranspose2d(\n",
    "                    in_channels=self.in_channels,\n",
    "                    out_channels=self.in_channels // 2,\n",
    "                    kernel_size=self.kernel_size,\n",
    "                    stride=self.stride_size,\n",
    "                    padding=self.padding_size,\n",
    "                )\n",
    "            )\n",
    "\n",
    "            self.upsampleBlocks.append(\n",
    "                nn.InstanceNorm2d(num_features=self.in_channels // 2)\n",
    "            )\n",
    "            self.upsampleBlocks.append(nn.LeakyReLU(negative_slope=0.2, inplace=True))\n",
    "\n",
    "            self.in_channels //= 2\n",
    "\n",
    "        self.modelBlocks.append(nn.Sequential(*self.upsampleBlocks))\n",
    "\n",
    "        self.modelBlocks.append(\n",
    "            nn.Sequential(\n",
    "                nn.ReflectionPad2d(padding=self.kernel_size - 1),\n",
    "                nn.Conv2d(\n",
    "                    in_channels=self.in_channels,\n",
    "                    out_channels=self.kernel_size - 1,\n",
    "                    kernel_size=self.kernel_size + 3,\n",
    "                ),\n",
    "                nn.Tanh(),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.modelBlocks = nn.Sequential(*self.modelBlocks)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        if isinstance(x, torch.Tensor):\n",
    "            x = self.sharedBlock(x)\n",
    "            return self.modelBlocks(x)\n",
    "        else:\n",
    "            raise ValueError(\"Input should be the tensor type\".capitalize())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    image_channels = 256\n",
    "\n",
    "    batch_size = 1\n",
    "    image_size = 32\n",
    "\n",
    "    shared_G = ResidualBlock(in_channels=image_channels)\n",
    "\n",
    "    netG1 = Generator(\n",
    "        in_channels=image_channels,\n",
    "        sharedBlock=ResidualBlock(in_channels=image_channels),\n",
    "    )\n",
    "    netG2 = Generator(\n",
    "        in_channels=image_channels,\n",
    "        sharedBlock=ResidualBlock(in_channels=image_channels),\n",
    "    )\n",
    "\n",
    "    generatedImage1 = netG1(\n",
    "        torch.randn(batch_size, image_channels, image_size, image_size)\n",
    "    )\n",
    "    generatedImage2 = netG2(\n",
    "        torch.randn(batch_size, image_channels, image_size, image_size)\n",
    "    )\n",
    "\n",
    "    assert (\n",
    "        generatedImage1.size() == generatedImage2.size()\n",
    "    ), \"Shape mismatch(generatedImage1, generatedImage2)\".capitalize()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPSG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
