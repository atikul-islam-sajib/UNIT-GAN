{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import torch\n",
    "import zipfile\n",
    "import argparse\n",
    "import warnings\n",
    "import traceback\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchview import draw_graph\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import joblib\n",
    "\n",
    "\n",
    "def dump(filename=None, value=None):\n",
    "    if (filename is not None) and (value is not None):\n",
    "        joblib.dump(value=value, filename=filename)\n",
    "    else:\n",
    "        raise ValueError(\"Could not dump file\".capitalize())\n",
    "\n",
    "\n",
    "def load(filename=None):\n",
    "    if filename is not None:\n",
    "        return joblib.load(filename=filename)\n",
    "    else:\n",
    "        raise ValueError(\"Could not load file\".capitalize())\n",
    "\n",
    "\n",
    "def config():\n",
    "    with open(\"../config.yml\", \"r\") as file:\n",
    "        return yaml.safe_load(file)\n",
    "\n",
    "\n",
    "def device_init(device: str = \"cuda\"):\n",
    "    if device == \"cuda\":\n",
    "        return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    elif device == \"mps\":\n",
    "        return torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "def weight_init(m):\n",
    "    classname = m.__class__.__name\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find(\"BatchNorm\") != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "\n",
    "def clean_folders():\n",
    "    train_models = \"../artifacts/train_models/\"\n",
    "    best_model = \"../artifacts/best_model/\"\n",
    "    metrics_path = \"../artifacts/metrics_path/\"\n",
    "    train_images = \"../artifacts/train_images/\"\n",
    "    test_image = \"../artifacts/test_image/\"\n",
    "\n",
    "    for folder in tqdm(\n",
    "        [train_images, test_image, train_models, best_model, metrics_path]\n",
    "    ):\n",
    "        for file in os.listdir(folder):\n",
    "            file_path = os.path.join(folder, file)\n",
    "            try:\n",
    "                if os.path.isfile(file_path):\n",
    "                    os.remove(file_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error occurred while cleaning folder: {folder}\")\n",
    "                print(f\"Error: {e}\")\n",
    "\n",
    "        print(\"All files have been deleted.\".capitalize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "class Loader:\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset=None,\n",
    "        image_size: int = 128,\n",
    "        batch_size: int = 1,\n",
    "        split_size: float = 0.20,\n",
    "    ):\n",
    "        self.dataset = dataset\n",
    "        self.image_size = image_size\n",
    "        self.batch_size = batch_size\n",
    "        self.split_size = split_size\n",
    "\n",
    "        self.imageA = []\n",
    "        self.imageB = []\n",
    "\n",
    "    def unzip_folder(self):\n",
    "        os.makedirs(config()[\"path\"][\"processed_path\"], exist_ok=True)\n",
    "\n",
    "        with zipfile.ZipFile(self.dataset, mode=\"r\") as zip_ref:\n",
    "            zip_ref.extractall(path=config()[\"path\"][\"processed_path\"])\n",
    "\n",
    "        print(f\"\"\"Unzip folder {config()[\"path\"][\"processed_path\"]}\"\"\".capitalize())\n",
    "\n",
    "    def split_dataset(self, X: list, y: list):\n",
    "        if isinstance(X, list) and isinstance(y, list):\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y, test_size=self.split_size, random_state=42\n",
    "            )\n",
    "            return {\n",
    "                \"X_train\": X_train,\n",
    "                \"X_test\": X_test,\n",
    "                \"y_train\": y_train,\n",
    "                \"y_test\": y_test,\n",
    "            }\n",
    "\n",
    "    def transforms(self, type: str = \"image\"):\n",
    "        if type == \"image\":\n",
    "            return transforms.Compose(\n",
    "                [\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Resize(\n",
    "                        (self.image_size, self.image_size), Image.BICUBIC\n",
    "                    ),\n",
    "                    transforms.CenterCrop((self.image_size, self.image_size)),\n",
    "                    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            return transforms.Compose(\n",
    "                [\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Resize((self.image_size, self.image_size)),\n",
    "                    transforms.CenterCrop((self.image_size, self.image_size)),\n",
    "                    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "    def features_extractor(self):\n",
    "        dataset_path = os.path.join(config()[\"path\"][\"processed_path\"], \"dataset\")\n",
    "\n",
    "        images_path = os.path.join(dataset_path, \"X\")\n",
    "        masks_path = os.path.join(dataset_path, \"y\")\n",
    "\n",
    "        for image in tqdm(os.listdir(images_path)):\n",
    "            if image.endswith((\".jpg\", \".jpeg\", \".png\")) and (\n",
    "                image in os.path.join(masks_path, image)\n",
    "            ):\n",
    "                image_path = os.path.join(images_path, image)\n",
    "                mask_path = os.path.join(masks_path, image)\n",
    "\n",
    "                if not os.path.exists(image_path):\n",
    "                    print(f\"Image not found: {image_path}\")\n",
    "                    continue\n",
    "                if not os.path.exists(mask_path):\n",
    "                    print(f\"Mask not found: {mask_path}\")\n",
    "                    continue\n",
    "\n",
    "                X = cv2.imread(image_path)\n",
    "                y = cv2.imread(mask_path)\n",
    "\n",
    "                X = cv2.cvtColor(X, cv2.COLOR_BGR2RGB)\n",
    "                y = cv2.cvtColor(y, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                X = self.transforms(type=\"image\")(Image.fromarray(X))\n",
    "                y = self.transforms()(Image.fromarray(y))\n",
    "\n",
    "                self.imageA.append(X)\n",
    "                self.imageB.append(y)\n",
    "\n",
    "        assert len(self.imageA) == len(self.imageB)\n",
    "\n",
    "        try:\n",
    "            return self.split_dataset(X=self.imageA, y=self.imageB)\n",
    "        except AssertionError as e:\n",
    "            print(f\"Assertion error: {e}\")\n",
    "            sys.exit(1)\n",
    "\n",
    "    def create_dataloader(self):\n",
    "        try:\n",
    "            dataset = self.features_extractor()\n",
    "\n",
    "            train_dataloader = DataLoader(\n",
    "                dataset=list(zip(dataset[\"X_train\"], dataset[\"y_train\"])),\n",
    "                batch_size=self.batch_size,\n",
    "                shuffle=True,\n",
    "            )\n",
    "            valid_dataloader = DataLoader(\n",
    "                dataset=list(zip(dataset[\"X_test\"], dataset[\"y_test\"])),\n",
    "                batch_size=self.batch_size * 16,\n",
    "                shuffle=True,\n",
    "            )\n",
    "\n",
    "            for filename, dataloader in [\n",
    "                (\"train_dataloader\", train_dataloader),\n",
    "                (\"valid_dataloader\", valid_dataloader),\n",
    "            ]:\n",
    "                dump(\n",
    "                    filename=os.path.join(\n",
    "                        \"../data/processed/\", filename + \".pkl\"\n",
    "                    ),\n",
    "                    value=dataloader,\n",
    "                )\n",
    "\n",
    "            print(\n",
    "                \"Train and valid dataloader saved successfully in the folder {}\".format(\n",
    "                    \"../data/processed/\"\n",
    "                ).capitalize()\n",
    "            )\n",
    "\n",
    "        except AssertionError as e:\n",
    "            print(f\"Assertion error: {e}\")\n",
    "            traceback.print_exc()\n",
    "            sys.exit(1)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            traceback.print_exc()\n",
    "            sys.exit(1)\n",
    "\n",
    "    @staticmethod\n",
    "    def display_images():\n",
    "        processed_path = os.path.join(config()[\"path\"][\"processed_path\"])\n",
    "        if os.path.exists(processed_path):\n",
    "            train_dataloder = os.path.join(processed_path, \"train_dataloader.pkl\")\n",
    "            valid_dataloder = os.path.join(processed_path, \"valid_dataloader.pkl\")\n",
    "\n",
    "            train_dataloder = load(filename=train_dataloder)\n",
    "            valid_dataloder = load(filename=valid_dataloder)\n",
    "\n",
    "            valid_X, valid_Y = next(iter(valid_dataloder))\n",
    "\n",
    "            num_of_rows = valid_X.size(0) // 2\n",
    "            num_of_cols = valid_X.size(0) // num_of_rows\n",
    "\n",
    "            plt.figure(figsize=(10, 20))\n",
    "\n",
    "            for index, X in enumerate(valid_X):\n",
    "                X = X.squeeze().permute(2, 1, 0).detach().cpu().numpy()\n",
    "                y = valid_Y[index].squeeze().permute(2, 1, 0).detach().cpu().numpy()\n",
    "\n",
    "                X = (X - X.min()) / (X.max() - X.min())\n",
    "                y = (y - y.min()) / (y.max() - y.min())\n",
    "\n",
    "                plt.subplot(2 * num_of_rows, 2 * num_of_cols, 2 * index + 1)\n",
    "                plt.imshow(X)\n",
    "                plt.title(\"X\")\n",
    "                plt.axis(\"off\")\n",
    "\n",
    "                plt.subplot(2 * num_of_rows, 2 * num_of_cols, 2 * index + 2)\n",
    "                plt.imshow(y)\n",
    "                plt.title(\"Y\")\n",
    "                plt.axis(\"off\")\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(\"../artifacts/files/\", \"images.png\"))\n",
    "            plt.show()\n",
    "\n",
    "    @staticmethod\n",
    "    def dataset_details():\n",
    "        processed_path = os.path.join(config()[\"path\"][\"processed_path\"])\n",
    "        if os.path.exists(processed_path):\n",
    "            train_dataloder = os.path.join(processed_path, \"train_dataloader.pkl\")\n",
    "            valid_dataloder = os.path.join(processed_path, \"valid_dataloader.pkl\")\n",
    "\n",
    "            train_dataloder = load(filename=train_dataloder)\n",
    "            valid_dataloder = load(filename=valid_dataloder)\n",
    "\n",
    "            train_X, train_Y = next(iter(train_dataloder))\n",
    "            valid_X, valid_Y = next(iter(valid_dataloder))\n",
    "\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"Train X Shape\": str(train_X.size()),\n",
    "                    \"Train Y Shape\": str(train_Y.size()),\n",
    "                    \"Valid X Shape\": str(valid_X.size()),\n",
    "                    \"Valid Y Shape\": str(valid_Y.size()),\n",
    "                    \"total_train_dataset\": sum(X.size(0) for X, _ in train_dataloder),\n",
    "                    \"total_valid_dataset\": sum(X.size(0) for X, _ in valid_dataloder),\n",
    "                    \"total_dataset\": (sum(X.size(0) for X, _ in train_dataloder))\n",
    "                    + sum(Y.size(0) for Y, _ in valid_dataloder),\n",
    "                },\n",
    "                index=[\"Dataset Details\"],\n",
    "            ).T.to_csv(\n",
    "                os.path.join(\"../artifacts/files\", \"dataset_details.csv\"),\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            print(f\"Folder {processed_path} does not exist\".capitalize())\n",
    "            sys.exit(1)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    loader = Loader(dataset=\"../data/raw/dataset.zip\", batch_size=1, split_size=0.20)\n",
    "\n",
    "    loader.unzip_folder()\n",
    "    loader.create_dataloader()\n",
    "\n",
    "    Loader.dataset_details()\n",
    "    Loader.display_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int = 256):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = in_channels\n",
    "\n",
    "        self.reflectionpad2d = 1\n",
    "        self.kernel_size = 3\n",
    "        self.stride_size = 1\n",
    "\n",
    "        self.layers = []\n",
    "\n",
    "        for index in range(2):\n",
    "            self.layers.append(nn.ReflectionPad2d(self.reflectionpad2d))\n",
    "\n",
    "            self.layers.append(\n",
    "                nn.Conv2d(\n",
    "                    in_channels=self.in_channels,\n",
    "                    out_channels=self.out_channels,\n",
    "                    kernel_size=self.kernel_size,\n",
    "                    stride=self.stride_size,\n",
    "                )\n",
    "            )\n",
    "\n",
    "            self.layers.append(nn.InstanceNorm2d(num_features=self.out_channels))\n",
    "\n",
    "            if index != 1:\n",
    "                self.layers.append(nn.ReLU())\n",
    "\n",
    "        self.residualBlock = nn.Sequential(*self.layers)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        if isinstance(x, torch.Tensor):\n",
    "            return x + self.residualBlock(x)\n",
    "        else:\n",
    "            raise ValueError(\"Input should be the tensor type\".capitalize())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    image_channels = 256\n",
    "    residual = nn.Sequential(\n",
    "        *[ResidualBlock(in_channels=image_channels) for _ in range(3)]\n",
    "    )\n",
    "\n",
    "    print(residual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels: int = 3, sharedBlocks=None):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = int(math.pow(2, self.in_channels + self.in_channels))\n",
    "        self.kerenl_size = (self.in_channels * 2) + 1\n",
    "\n",
    "        if not isinstance(sharedBlocks, ResidualBlock):\n",
    "            raise ValueError(\n",
    "                \"shared_block must be an instance of ResidualBlock\".capitalize()\n",
    "            )\n",
    "\n",
    "        self.sharedBlocks = sharedBlocks\n",
    "\n",
    "        self.modelBlocks = list()\n",
    "        self.downLayers = list()\n",
    "\n",
    "        self.modelBlocks.append(\n",
    "            nn.Sequential(\n",
    "                nn.ReflectionPad2d(padding=self.in_channels),\n",
    "                nn.Conv2d(\n",
    "                    in_channels=self.in_channels,\n",
    "                    out_channels=self.out_channels,\n",
    "                    kernel_size=self.kerenl_size,\n",
    "                ),\n",
    "                nn.InstanceNorm2d(num_features=self.out_channels),\n",
    "                nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        for _ in range(2):\n",
    "            self.downLayers.append(\n",
    "                nn.Conv2d(\n",
    "                    in_channels=self.out_channels,\n",
    "                    out_channels=self.out_channels * 2,\n",
    "                    kernel_size=self.kerenl_size // 2,\n",
    "                    stride=(self.in_channels // self.in_channels) + 1,\n",
    "                    padding=self.in_channels // self.in_channels,\n",
    "                )\n",
    "            )\n",
    "            self.downLayers.append(\n",
    "                nn.InstanceNorm2d(num_features=self.out_channels * 2)\n",
    "            )\n",
    "            self.downLayers.append(nn.ReLU())\n",
    "\n",
    "            self.out_channels *= 2\n",
    "\n",
    "        self.modelBlocks.append(nn.Sequential(*self.downLayers))\n",
    "\n",
    "        self.modelBlocks.append(\n",
    "            nn.Sequential(\n",
    "                *[ResidualBlock(in_channels=self.out_channels) for _ in range(3)]\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.modelBlocks = nn.Sequential(*self.modelBlocks)\n",
    "\n",
    "    def reparameterization(self, mu: torch.Tensor):\n",
    "        if isinstance(mu, torch.Tensor):\n",
    "            z = torch.randn_like(mu)\n",
    "            return mu + z\n",
    "        else:\n",
    "            raise ValueError(\"Input should be the tensor type\".capitalize())\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        if isinstance(x, torch.Tensor):\n",
    "            x = self.modelBlocks(x)\n",
    "            mu = self.sharedBlocks(x)\n",
    "            z = self.reparameterization(mu)\n",
    "\n",
    "            return mu, z\n",
    "        else:\n",
    "            raise ValueError(\"Input should be the tensor type\".capitalize())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    in_channels = 3\n",
    "\n",
    "    batch_size = 1\n",
    "    image_size = 128\n",
    "\n",
    "    shared_E = ResidualBlock(\n",
    "        in_channels=int(in_channels * (math.pow(2, 8) - 1) / in_channels + 1)\n",
    "    )\n",
    "\n",
    "    encoder1 = Encoder(in_channels=in_channels, sharedBlocks=shared_E)\n",
    "    encoder2 = Encoder(in_channels=in_channels, sharedBlocks=shared_E)\n",
    "\n",
    "    mu1, z1 = encoder1(torch.randn(batch_size, in_channels, image_size, image_size))\n",
    "    mu2, z2 = encoder2(torch.randn(batch_size, in_channels, image_size, image_size))\n",
    "\n",
    "    assert (\n",
    "        mu1.size() == mu2.size() == z1.size() == z2.size()\n",
    "    ), \"Shape mismatch(mu1, mu2) and (z1, z2)\".capitalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, in_channels: int = 256, sharedBlock: ResidualBlock = None):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = self.in_channels\n",
    "\n",
    "        self.kernel_size = int(math.sqrt(math.sqrt(self.in_channels)))\n",
    "        self.stride_size = int(math.sqrt(self.kernel_size))\n",
    "        self.padding_size = self.stride_size // self.stride_size\n",
    "\n",
    "        if isinstance(sharedBlock, ResidualBlock):\n",
    "            self.sharedBlock = sharedBlock\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"shared_block must be an instance of ResidualBlock\".capitalize()\n",
    "            )\n",
    "\n",
    "        self.modelBlocks = []\n",
    "        self.upsampleBlocks = []\n",
    "\n",
    "        self.modelBlocks.append(\n",
    "            nn.Sequential(\n",
    "                *[ResidualBlock(in_channels=self.in_channels) for _ in range(3)]\n",
    "            )\n",
    "        )\n",
    "\n",
    "        for _ in range(2):\n",
    "            self.upsampleBlocks.append(\n",
    "                nn.ConvTranspose2d(\n",
    "                    in_channels=self.in_channels,\n",
    "                    out_channels=self.in_channels // 2,\n",
    "                    kernel_size=self.kernel_size,\n",
    "                    stride=self.stride_size,\n",
    "                    padding=self.padding_size,\n",
    "                )\n",
    "            )\n",
    "\n",
    "            self.upsampleBlocks.append(\n",
    "                nn.InstanceNorm2d(num_features=self.in_channels // 2)\n",
    "            )\n",
    "            self.upsampleBlocks.append(nn.LeakyReLU(negative_slope=0.2, inplace=True))\n",
    "\n",
    "            self.in_channels //= 2\n",
    "\n",
    "        self.modelBlocks.append(nn.Sequential(*self.upsampleBlocks))\n",
    "\n",
    "        self.modelBlocks.append(\n",
    "            nn.Sequential(\n",
    "                nn.ReflectionPad2d(padding=self.kernel_size - 1),\n",
    "                nn.Conv2d(\n",
    "                    in_channels=self.in_channels,\n",
    "                    out_channels=self.kernel_size - 1,\n",
    "                    kernel_size=self.kernel_size + 3,\n",
    "                ),\n",
    "                nn.Tanh(),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.modelBlocks = nn.Sequential(*self.modelBlocks)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        if isinstance(x, torch.Tensor):\n",
    "            x = self.sharedBlock(x)\n",
    "            return self.modelBlocks(x)\n",
    "        else:\n",
    "            raise ValueError(\"Input should be the tensor type\".capitalize())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    image_channels = 256\n",
    "\n",
    "    batch_size = 1\n",
    "    image_size = 32\n",
    "\n",
    "    shared_G = ResidualBlock(in_channels=image_channels)\n",
    "\n",
    "    netG1 = Generator(\n",
    "        in_channels=image_channels,\n",
    "        sharedBlock=ResidualBlock(in_channels=image_channels),\n",
    "    )\n",
    "    netG2 = Generator(\n",
    "        in_channels=image_channels,\n",
    "        sharedBlock=ResidualBlock(in_channels=image_channels),\n",
    "    )\n",
    "\n",
    "    generatedImage1 = netG1(\n",
    "        torch.randn(batch_size, image_channels, image_size, image_size)\n",
    "    )\n",
    "    generatedImage2 = netG2(\n",
    "        torch.randn(batch_size, image_channels, image_size, image_size)\n",
    "    )\n",
    "\n",
    "    assert (\n",
    "        generatedImage1.size() == generatedImage2.size()\n",
    "    ), \"Shape mismatch(generatedImage1, generatedImage2)\".capitalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels: int = 3):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = int(math.pow(2, self.in_channels + self.in_channels))\n",
    "\n",
    "        self.kernel_size = self.in_channels + 1\n",
    "        self.stride_size = self.kernel_size // 2\n",
    "        self.padding_size = self.stride_size // 2\n",
    "\n",
    "        self.layers = list()\n",
    "\n",
    "        for index in range(4):\n",
    "            self.layers.append(\n",
    "                nn.Conv2d(\n",
    "                    in_channels=self.in_channels,\n",
    "                    out_channels=self.out_channels,\n",
    "                    kernel_size=self.kernel_size,\n",
    "                    stride=self.stride_size,\n",
    "                    padding=self.padding_size,\n",
    "                )\n",
    "            )\n",
    "\n",
    "            if index != 0:\n",
    "                self.layers.append(nn.InstanceNorm2d(num_features=self.out_channels))\n",
    "\n",
    "            self.layers.append(nn.LeakyReLU(negative_slope=0.2, inplace=True))\n",
    "\n",
    "            self.in_channels = self.out_channels\n",
    "            self.out_channels = self.out_channels * 2\n",
    "\n",
    "        self.layers.append(\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    in_channels=self.in_channels,\n",
    "                    out_channels=self.in_channels // self.in_channels,\n",
    "                    kernel_size=self.kernel_size - 1,\n",
    "                    stride=self.stride_size - 1,\n",
    "                    padding=self.padding_size,\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.model = nn.Sequential(*self.layers)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        if isinstance(x, torch.Tensor):\n",
    "            return self.model(x)\n",
    "        else:\n",
    "            raise ValueError(\"Input should be the tensor type\".capitalize())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    image_channels = 3\n",
    "\n",
    "    batch_size = 1\n",
    "    image_size = 128\n",
    "\n",
    "    netD = Discriminator(in_channels=image_channels)\n",
    "\n",
    "    assert netD(\n",
    "        torch.randn(batch_size, image_channels, image_size, image_size)\n",
    "    ).size() == torch.Size(\n",
    "        [\n",
    "            batch_size,\n",
    "            image_channels // image_channels,\n",
    "            image_size // 16,\n",
    "            image_size // 16,\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GANLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANLoss(nn.Module):\n",
    "    def __init__(self, reduction: str = \"mean\"):\n",
    "        super(GANLoss, self).__init__()\n",
    "\n",
    "        self.name = \"GANLoss for the UNIT-GAN\"\n",
    "        self.reduction = reduction\n",
    "        self.loss = nn.MSELoss(reduction=self.reduction)\n",
    "\n",
    "    def forward(self, predicted: torch.Tensor, actual: torch.Tensor):\n",
    "        if isinstance(predicted, torch.Tensor) and isinstance(actual, torch.Tensor):\n",
    "            return self.loss(predicted, actual)\n",
    "        else:\n",
    "            raise ValueError(\"Predicted and actual should be both tensor\".capitalize())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    loss = GANLoss(reduction=\"mean\")\n",
    "\n",
    "    actual = torch.tensor([1.0, 0.0, 1.0, 1.0])\n",
    "    predicted = torch.tensor([1.0, 0.0, 1.0, 1.0])\n",
    "\n",
    "    print(loss(predicted, actual))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PixelLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PixelLoss(nn.Module):\n",
    "    def __init__(self, reduction: str = \"mean\"):\n",
    "        super(PixelLoss, self).__init__()\n",
    "\n",
    "        self.name = \"L1Loss for the UNIT-GAN\"\n",
    "        self.reduction = reduction\n",
    "\n",
    "        self.loss = nn.L1Loss(reduction=self.reduction)\n",
    "\n",
    "    def forward(self, predicted: torch.Tensor, actual: torch.Tensor):\n",
    "        if isinstance(predicted, torch.Tensor) and isinstance(actual, torch.Tensor):\n",
    "            return self.loss(predicted, actual)\n",
    "        else:\n",
    "            raise ValueError(\"Predicted and actual should be in tensor\".capitalize())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    loss = PixelLoss(reduction=\"mean\")\n",
    "\n",
    "    actual = torch.tensor([1.0, 0.0, 1.0, 1.0])\n",
    "    predicted = torch.tensor([1.0, 0.0, 1.0, 1.0])\n",
    "\n",
    "    print(loss(predicted, actual))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KL Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KLDivergence(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(KLDivergence, self).__init__()\n",
    "        self.name = \"KL Divergence\".title()\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        if isinstance(x, torch.Tensor):\n",
    "            return torch.mean(torch.pow(x, 2))\n",
    "        else:\n",
    "            raise ValueError(\"X should be the type of torch.Tensor\".capitalize())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    batch_size = config()[\"dataloader\"][\"batch_size\"]\n",
    "\n",
    "    loss = KLDivergence()\n",
    "\n",
    "    predicted = torch.randn((batch_size, 64))\n",
    "\n",
    "    assert (\n",
    "        type(loss(predicted)) == torch.Tensor\n",
    "    ), \"Output should be the torch.Tensor\".capitalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def load_dataloader():\n",
    "    processed_path = \"../data/processed/\"\n",
    "    if os.path.exists(processed_path):\n",
    "        train_dataloader = os.path.join(processed_path, \"train_dataloader.pkl\")\n",
    "        valid_dataloader = os.path.join(processed_path, \"valid_dataloader.pkl\")\n",
    "\n",
    "        train_dataloader = load(filename=train_dataloader)\n",
    "        valid_dataloader = load(filename=valid_dataloader)\n",
    "\n",
    "        return {\n",
    "            \"train_dataloader\": train_dataloader,\n",
    "            \"valid_dataloader\": valid_dataloader,\n",
    "        }\n",
    "\n",
    "\n",
    "def helper(**kwargs):\n",
    "    lr = kwargs[\"lr\"]\n",
    "    beta1 = kwargs[\"beta1\"]\n",
    "    beta2 = kwargs[\"beta2\"]\n",
    "    momentum = kwargs[\"momentum\"]\n",
    "    adam = kwargs[\"adam\"]\n",
    "    SGD = kwargs[\"SGD\"]\n",
    "\n",
    "    shared_E = ResidualBlock(in_channels=256)\n",
    "    shared_G = ResidualBlock(in_channels=256)\n",
    "\n",
    "    E1 = Encoder(\n",
    "        in_channels=config()[\"dataloader\"][\"image_channels\"], sharedBlocks=shared_E\n",
    "    )\n",
    "    E2 = Encoder(\n",
    "        in_channels=config()[\"dataloader\"][\"image_channels\"], sharedBlocks=shared_E\n",
    "    )\n",
    "\n",
    "    G1 = Generator(in_channels=256, sharedBlocks=shared_G)\n",
    "    G2 = Generator(in_channels=256, sharedBlocks=shared_G)\n",
    "\n",
    "    D1 = Discriminator(in_channels=config()[\"dataloader\"][\"image_channels\"])\n",
    "    D2 = Discriminator(in_channels=config()[\"dataloader\"][\"image_channels\"])\n",
    "\n",
    "    if adam:\n",
    "        optimizerG = optim.Adam(\n",
    "            params=list(E1.parameters())\n",
    "            + list(E2.parameters())\n",
    "            + list(G1.parameters())\n",
    "            + list(G2.parameters()),\n",
    "            lr=lr,\n",
    "            betas=(beta1, beta2),\n",
    "        )\n",
    "        optimizerD1 = optim.Adam(params=D1.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "        optimizerD2 = optim.Adam(params=D2.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "\n",
    "    elif SGD:\n",
    "        optimizerG = optim.SGD(\n",
    "            params=list(E1.parameters())\n",
    "            + list(E2.parameters())\n",
    "            + list(G1.parameters())\n",
    "            + list(G2.parameters()),\n",
    "            lr=lr,\n",
    "            momentum=momentum,\n",
    "        )\n",
    "        optimizerD1 = optim.SGD(params=D1.parameters(), lr=lr, momentum=momentum)\n",
    "        optimizerD2 = optim.SGD(params=D2.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "    criterion = GANLoss(reduction=\"mean\")\n",
    "    pixelLoss = PixelLoss(reduction=\"mean\")\n",
    "\n",
    "    try:\n",
    "        dataset = load_dataloader()\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        traceback.print_exc()\n",
    "        sys.exit(1)\n",
    "\n",
    "    return {\n",
    "        \"train_dataloader\": dataset[\"train_dataloader\"],\n",
    "        \"valid_dataloader\": dataset[\"valid_dataloader\"],\n",
    "        \"E1\": E1,\n",
    "        \"E2\": E2,\n",
    "        \"netG1\": G1,\n",
    "        \"netG2\": G2,\n",
    "        \"netD1\": D1,\n",
    "        \"netD2\": D2,\n",
    "        \"optimizerG\": optimizerG,\n",
    "        \"optimizerD1\": optimizerD1,\n",
    "        \"optimizerD2\": optimizerD2,\n",
    "        \"criterion\": criterion,\n",
    "        \"pixelLoss\": pixelLoss,\n",
    "    }\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    init = helper(\n",
    "        lr=2e-4,\n",
    "        beta1=0.5,\n",
    "        beta2=0.999,\n",
    "        momentum=0.95,\n",
    "        adam=True,\n",
    "        SGD=False,\n",
    "    )\n",
    "\n",
    "    train_dataloader = init[\"train_dataloader\"]\n",
    "    valid_dataloader = init[\"valid_dataloader\"]\n",
    "\n",
    "    encoder1 = init[\"E1\"]\n",
    "    encoder2 = init[\"E2\"]\n",
    "\n",
    "    netG1 = init[\"netG1\"]\n",
    "    netG2 = init[\"netG2\"]\n",
    "\n",
    "    netD1 = init[\"netD1\"]\n",
    "    netD2 = init[\"netD2\"]\n",
    "\n",
    "    optimizerG = init[\"optimizerG\"]\n",
    "    optimizerD1 = init[\"optimizerD1\"]\n",
    "    optimizerD2 = init[\"optimizerD2\"]\n",
    "\n",
    "    criterion = init[\"criterion\"]\n",
    "    pixelLoss = init[\"pixelLoss\"]\n",
    "\n",
    "    assert (\n",
    "        train_dataloader.__class__ == torch.utils.data.DataLoader\n",
    "    ), \"Train dataloader shoould be torch.utils.data.DataLoader\".capitalize()\n",
    "    assert (\n",
    "        valid_dataloader.__class__ == torch.utils.data.DataLoader\n",
    "    ), \"Valid dataloader shoould be torch.utils.data.DataLoader\".capitalize()\n",
    "\n",
    "    assert (\n",
    "        encoder1.__class__ == Encoder\n",
    "    ), \"Encoder object should be Encoder class\".capitalize()\n",
    "    assert (\n",
    "        encoder2.__class__ == Encoder\n",
    "    ), \"Encoder object should be Encoder class\".capitalize()\n",
    "\n",
    "    assert (\n",
    "        netG1.__class__ == Generator\n",
    "    ), \"Generator object should be Generator class\".capitalize()\n",
    "    assert (\n",
    "        netG2.__class__ == Generator\n",
    "    ), \"Generator object should be Generator class\".capitalize()\n",
    "\n",
    "    assert (\n",
    "        netD1.__class__ == Discriminator\n",
    "    ), \"netD1 object should be Discriminator class\".capitalize()\n",
    "    assert (\n",
    "        netD2.__class__ == Discriminator\n",
    "    ), \"netD2 object should be Discriminator class\".capitalize()\n",
    "\n",
    "    assert (\n",
    "        optimizerG.__class__ == optim.Adam\n",
    "    ), \"optimizerG object should be Adam class\".capitalize()\n",
    "    assert (\n",
    "        optimizerD1.__class__ == optim.Adam\n",
    "    ), \"optimizerD1 object should be Adam class\".capitalize()\n",
    "    assert (\n",
    "        optimizerD2.__class__ == optim.Adam\n",
    "    ), \"optimizerD2 object should be Adam class\".capitalize()\n",
    "\n",
    "    assert (\n",
    "        criterion.__class__ == GANLoss\n",
    "    ), \"Criterion object should be GANLoss class\".capitalize()\n",
    "    assert (\n",
    "        pixelLoss.__class__ == PixelLoss\n",
    "    ), \"pixelLoss object should be PixelLoss class\".capitalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        epochs: int = 500,\n",
    "        lr: float = 2e-5,\n",
    "        beta1: float = 0.5,\n",
    "        beta2: float = 0.999,\n",
    "        momentum: float = 0.95,\n",
    "        adam: bool = True,\n",
    "        SGD: bool = False,\n",
    "        device: str = \"cuda\",\n",
    "        l1_regularization: bool = False,\n",
    "        l2_regularization: float = False,\n",
    "        elasticNet_regularization: bool = False,\n",
    "        verbose: bool = True,\n",
    "        mlFlow: bool = True,\n",
    "    ):\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.momentum = momentum\n",
    "        self.adam = adam\n",
    "        self.SGD = SGD\n",
    "        self.device = device\n",
    "        self.l1_regularization = l1_regularization\n",
    "        self.l2_regularization = l2_regularization\n",
    "        self.elasticNet_regularization = elasticNet_regularization\n",
    "        self.verbose = verbose\n",
    "        self.mlFlow = mlFlow\n",
    "\n",
    "        self.device = device_init(device=self.device)\n",
    "\n",
    "        self.init = helper(\n",
    "            lr=self.lr,\n",
    "            beta1=self.beta1,\n",
    "            beta2=self.beta2,\n",
    "            momentum=self.momentum,\n",
    "            adam=self.adam,\n",
    "            SGD=self.SGD,\n",
    "        )\n",
    "\n",
    "        self.train_dataloader = self.init[\"train_dataloader\"]\n",
    "        self.valid_dataloader = self.init[\"valid_dataloader\"]\n",
    "\n",
    "        self.encoder1 = self.init[\"E1\"].to(self.device)\n",
    "        self.encoder2 = self.init[\"E2\"].to(self.device)\n",
    "\n",
    "        self.netG1 = self.init[\"netG1\"].to(self.device)\n",
    "        self.netG2 = self.init[\"netG2\"].to(self.device)\n",
    "\n",
    "        self.netD1 = self.init[\"netD1\"].to(self.device)\n",
    "        self.netD2 = self.init[\"netD2\"].to(self.device)\n",
    "\n",
    "        self.optimizerG = self.init[\"optimizerG\"]\n",
    "        self.optimizerD1 = self.init[\"optimizerD1\"]\n",
    "        self.optimizerD2 = self.init[\"optimizerD2\"]\n",
    "\n",
    "        self.criterion = self.init[\"criterion\"]\n",
    "        self.pixelLoss = self.init[\"pixelLoss\"]\n",
    "        self.kl_loss = self.init[\"kl_loss\"]\n",
    "\n",
    "        assert (\n",
    "            self.train_dataloader.__class__ == torch.utils.data.DataLoader\n",
    "        ), \"Train dataloader shoould be torch.utils.data.DataLoader\".capitalize()\n",
    "        assert (\n",
    "            self.valid_dataloader.__class__ == torch.utils.data.DataLoader\n",
    "        ), \"Valid dataloader shoould be torch.utils.data.DataLoader\".capitalize()\n",
    "\n",
    "        assert (\n",
    "            self.encoder1.__class__ == Encoder\n",
    "        ), \"Encoder object should be Encoder class\".capitalize()\n",
    "        assert (\n",
    "            self.encoder2.__class__ == Encoder\n",
    "        ), \"Encoder object should be Encoder class\".capitalize()\n",
    "\n",
    "        assert (\n",
    "            self.netG1.__class__ == Generator\n",
    "        ), \"Generator object should be Generator class\".capitalize()\n",
    "        assert (\n",
    "            self.netG2.__class__ == Generator\n",
    "        ), \"Generator object should be Generator class\".capitalize()\n",
    "\n",
    "        assert (\n",
    "            self.netD1.__class__ == Discriminator\n",
    "        ), \"netD1 object should be Discriminator class\".capitalize()\n",
    "        assert (\n",
    "            self.netD2.__class__ == Discriminator\n",
    "        ), \"netD2 object should be Discriminator class\".capitalize()\n",
    "\n",
    "        assert (\n",
    "            self.optimizerG.__class__ == optim.Adam\n",
    "        ), \"optimizerG object should be Adam class\".capitalize()\n",
    "        assert (\n",
    "            self.optimizerD1.__class__ == optim.Adam\n",
    "        ), \"optimizerD1 object should be Adam class\".capitalize()\n",
    "        assert (\n",
    "            self.optimizerD2.__class__ == optim.Adam\n",
    "        ), \"optimizerD2 object should be Adam class\".capitalize()\n",
    "\n",
    "        assert (\n",
    "            self.criterion.__class__ == GANLoss\n",
    "        ), \"Criterion object should be GANLoss class\".capitalize()\n",
    "        assert (\n",
    "            self.pixelLoss.__class__ == PixelLoss\n",
    "        ), \"pixelLoss object should be PixelLoss class\".capitalize()\n",
    "        assert (\n",
    "            self.kl_loss.__class__ == KLDivergence\n",
    "        ), \"KL Divergence object should be PixelLoss class\".capitalize()\n",
    "\n",
    "    def l1_regularizer(self, model):\n",
    "        if model is not None:\n",
    "            return sum(torch.norm(params, 1) for params in model.parameters())\n",
    "        else:\n",
    "            raise TypeError(\n",
    "                \"Model should be passed in the l1 regularizer\".capitalize()()\n",
    "            )\n",
    "            \n",
    "    def l2_regularizer(self, model):\n",
    "        if model is not None:\n",
    "            return sum(torch.norm(params, 2) for params in model.parameters())\n",
    "        else:\n",
    "            raise TypeError(\n",
    "                \"Model should be passed in the l2 regularizer\".capitalize()()\n",
    "            )\n",
    "            \n",
    "    def elasticNet_regularizer(self, model):\n",
    "        if model is not None:\n",
    "            l1 = self.l1_regularization(model=model)\n",
    "            l2 = self.l2_regularization(model=model)\n",
    "            \n",
    "            return 0.01 * (l1 + l2)\n",
    "        else:\n",
    "            raise TypeError(\n",
    "                \"Model should be passed in the l2 regularizer\".capitalize()()\n",
    "            )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    trainer = Trainer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPSG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
